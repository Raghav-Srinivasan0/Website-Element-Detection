{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where I will process my data and run a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Model\n",
    "from keras import layers\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "import cv2 \n",
    "\n",
    "from get_coords import Data\n",
    "\n",
    "# do batch prediction function DONE\n",
    "# mix features together DONE\n",
    "# add color features DONE\n",
    "# mean square error for regression DONE\n",
    "# get started writing \n",
    "# get results 1/2 DONE\n",
    "\n",
    "# Features to try: DONE\n",
    "# 1) Raw Position Values DONE\n",
    "# Find how they did visual complexity \n",
    "# Think about why some features are doing better\n",
    "# try cross validation \n",
    "# reshuffle training and testing data\n",
    "# try removing some percent of training and test on different testing sets and train on different training sets\n",
    "# train should be different from test ALWAYS\n",
    "\n",
    "# start writing related works \n",
    "# start writing methodology\n",
    "# write indroduction\n",
    "# write like other papers that I have read\n",
    "\n",
    "# try to get positive results\n",
    "\n",
    "# arxiv for posting negative result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\woprg/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2022-11-2 Python-3.10.4 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "WARNING  NMS time limit 0.550s exceeded\n"
     ]
    }
   ],
   "source": [
    "classes = ['button', 'field', 'heading', 'iframe', 'image', 'label', 'link', 'text']\n",
    "\n",
    "directory = \"dataset/images/english/\"\n",
    "#directory = \"small_test/\"\n",
    "\n",
    "data_N = Data(\n",
    "    directory=directory,\n",
    "    pt=r'C:\\Users\\woprg\\Desktop\\CCIR\\LearningML\\TrainingYOLOv7_3\\yolov5\\runs\\train\\yolo_website6\\weights\\best.pt'\n",
    "    )\n",
    "\n",
    "raw_data = data_N.filter_confidence()\n",
    "image_names = list(raw_data.keys())\n",
    "image_path = data_N.images()\n",
    "images = {}\n",
    "\n",
    "for i in range(len(image_path)):\n",
    "    images[image_names[i]] = cv2.imread(image_path[i])\n",
    "\n",
    "def raw(d):\n",
    "    rawData = {}\n",
    "    temp = list(d.values())\n",
    "    for i in range(len(temp)):\n",
    "        temp_rawData = []\n",
    "        for element in temp[i]:\n",
    "            e = []\n",
    "            e.append(float((float(element[0])+float(element[2]))/2))\n",
    "            e.append(float((float(element[1])+float(element[3]))/2))\n",
    "            e.append(float(element[5]))\n",
    "            temp_rawData.extend(e)\n",
    "        rawData[int(image_names[i])] = temp_rawData\n",
    "    sizes = []\n",
    "    for i in range(len(rawData)):\n",
    "        sizes.append(len(rawData[i]))\n",
    "    max_size = max(sizes)\n",
    "    for i in range(len(rawData)):\n",
    "        if len(rawData[i]) < max_size:\n",
    "            for j in range(max_size - len(rawData[i])):\n",
    "                rawData[i].append(0)\n",
    "    return rawData\n",
    "    \n",
    "def raw():\n",
    "    rawData = {}\n",
    "    temp = list(raw_data.values())\n",
    "    for i in range(len(temp)):\n",
    "        temp_rawData = []\n",
    "        for element in temp[i]:\n",
    "            e = []\n",
    "            e.append(float((float(element[0])+float(element[2]))/2))\n",
    "            e.append(float((float(element[1])+float(element[3]))/2))\n",
    "            e.append(float(element[5]))\n",
    "            temp_rawData.extend(e)\n",
    "        rawData[int(image_names[i])] = temp_rawData\n",
    "    sizes = []\n",
    "    for i in range(len(rawData)):\n",
    "        sizes.append(len(rawData[i]))\n",
    "    max_size = max(sizes)\n",
    "    for i in range(len(rawData)):\n",
    "        if len(rawData[i]) < max_size:\n",
    "            for j in range(max_size - len(rawData[i])):\n",
    "                rawData[i].append(0)\n",
    "    return rawData\n",
    "\n",
    "def colorfulness():\n",
    "    colorfulness = {}\n",
    "    for i in range(len(list(images.values()))):\n",
    "        current_colorfulness = 0\n",
    "        count = 0\n",
    "        temp_image = list(images.values())[i] \n",
    "        hsv = cv2.cvtColor(temp_image, cv2.COLOR_BGR2HSV)\n",
    "        for row in range(len(hsv)):\n",
    "            for column in range(len(hsv[row])):\n",
    "                current_colorfulness = current_colorfulness + hsv[row][column][1] * hsv[row][column][2]\n",
    "                count = count + 1\n",
    "        result = current_colorfulness/count\n",
    "        colorfulness[int(list(images.keys())[i])] = result\n",
    "    return colorfulness\n",
    "\n",
    "def avgPos():\n",
    "    temp = list(raw_data.values())\n",
    "    avg_element_position = {}\n",
    "    for i in range(len(temp)):\n",
    "        avg_pixel_position_for_class = {}\n",
    "        count = {}\n",
    "        for element in temp[i]:\n",
    "            if avg_pixel_position_for_class.get(int(element[5])) == None:\n",
    "                avg_pixel_position_for_class[int(element[5])] = ((float(element[0])+float(element[2]))/2,(float(element[1])+float(element[3]))/2)\n",
    "                count[int(element[5])] = 1\n",
    "            else:\n",
    "                count[int(element[5])] += 1\n",
    "                avg_pixel_position_for_class[int(element[5])] = ((((float(element[0])+float(element[2]))/2)+avg_pixel_position_for_class[int(element[5])][0])/count[int(element[5])],(((float(element[1])+float(element[3]))/2)+avg_pixel_position_for_class[int(element[5])][0])/count[int(element[5])])\n",
    "                \n",
    "        avg_element_position[int(image_names[i])] = avg_pixel_position_for_class\n",
    "        #print(count)\n",
    "\n",
    "    return avg_element_position\n",
    "\n",
    "def freqQuad():\n",
    "    class_per_quadrant = {}\n",
    "    temp = list(raw_data.values())\n",
    "    for i in range(len(temp)):\n",
    "        temp_data_holder = [{},{},{},{}]\n",
    "        temp_data_holder_2 = []\n",
    "        temp_image_name = image_names[i]\n",
    "        temp_image = cv2.imread(directory + temp_image_name + '.png')\n",
    "        w = temp_image.shape[0]\n",
    "        h = temp_image.shape[1]\n",
    "        for element in temp[i]:\n",
    "            center_X = (element[0]+element[2])/2\n",
    "            center_Y = (element[1]+element[3])/2\n",
    "            if center_X >= w/2 and center_Y >= h/2:\n",
    "                if temp_data_holder[0].get(int(element[5])) == None:\n",
    "                    temp_data_holder[0][int(element[5])] = 1\n",
    "                else:\n",
    "                    temp_data_holder[0][int(element[5])] = temp_data_holder[0][int(element[5])] + 1\n",
    "            if center_X < w/2 and center_Y >= h/2:\n",
    "                if temp_data_holder[1].get(int(element[5])) == None:\n",
    "                    temp_data_holder[1][int(element[5])] = 1\n",
    "                else:\n",
    "                    temp_data_holder[1][int(element[5])] = temp_data_holder[1][int(element[5])] + 1\n",
    "            if center_X < w/2 and center_Y < h/2:\n",
    "                if temp_data_holder[2].get(int(element[5])) == None:\n",
    "                    temp_data_holder[2][int(element[5])] = 1\n",
    "                else:\n",
    "                    temp_data_holder[2][int(element[5])] = temp_data_holder[2][int(element[5])] + 1\n",
    "            if center_X >= w/2 and center_Y < h/2:\n",
    "                if temp_data_holder[3].get(int(element[5])) == None:\n",
    "                    temp_data_holder[3][int(element[5])] = 1\n",
    "                else:\n",
    "                    temp_data_holder[3][int(element[5])] = temp_data_holder[3][int(element[5])] + 1\n",
    "        for quadrant in temp_data_holder:\n",
    "            for i in range(8):\n",
    "                if quadrant.get(i) == None:\n",
    "                    temp_data_holder_2.append(0)\n",
    "                else:\n",
    "                    temp_data_holder_2.append(quadrant[i])\n",
    "        class_per_quadrant[int(temp_image_name)] = temp_data_holder_2\n",
    "    return class_per_quadrant\n",
    "    \n",
    "def freqClass():\n",
    "    dataX = {}\n",
    "    temp = list(raw_data.values())\n",
    "    for i in range(len(temp)):\n",
    "        per_image_data = {}\n",
    "        for element in temp[i]:\n",
    "            if per_image_data.get(int(element[5])) == None:\n",
    "                per_image_data[int(element[5])] = 1\n",
    "            else:\n",
    "                per_image_data[int(element[5])] = per_image_data[int(element[5])] + 1\n",
    "        dataX[int(image_names[i])] = per_image_data\n",
    "    return dataX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Mixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done feature mixer\n"
     ]
    }
   ],
   "source": [
    "# don't use raw\n",
    "# do all combinations of average position, class frequency, and quadrants\n",
    "# create table of results\n",
    "# create narrative surrounding results\n",
    "# base it off of related works and other papers\n",
    "\n",
    "def mixFeatures(avgPosition,quadrants,classfreq,raw,modeltype, c):\n",
    "\n",
    "    def createSVM(training, labels, apply_scaler2=True):\n",
    "        try:\n",
    "            for i in range(len(training)):\n",
    "                training[i] = list(training[i].values())\n",
    "        except Exception as e:\n",
    "            training = training\n",
    "        training_X = list(training)\n",
    "        labels_X = list(labels)\n",
    "        from sklearn import svm\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        if apply_scaler2:\n",
    "            scaler2 = StandardScaler()\n",
    "            data2 = scaler2.fit_transform(training_X)\n",
    "            #X = scaler2.fit(training)\n",
    "            #data2 = scaler2.transform(training)\n",
    "        else:\n",
    "            data2 = training_X\n",
    "        clf = svm.SVC()\n",
    "        clf.fit(data2, labels_X)\n",
    "        return clf\n",
    "\n",
    "    def createLin(training, labels, normalize=True):\n",
    "        try:\n",
    "            for i in range(len(training)):\n",
    "                training[i] = list(training[i].values())\n",
    "        except Exception as e:\n",
    "            training = training\n",
    "        if normalize:\n",
    "            normalizer = tf.keras.layers.Normalization(axis=-1)\n",
    "            normalizer.adapt(tf.convert_to_tensor(training))\n",
    "            linear_model = tf.keras.Sequential([\n",
    "                normalizer,\n",
    "                layers.Dense(units=1)\n",
    "            ])\n",
    "        else:\n",
    "            linear_model = tf.keras.Sequential([\n",
    "                layers.Dense(units=1)\n",
    "            ])\n",
    "\n",
    "        linear_model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.1),\n",
    "            loss='mean_squared_logarithmic_error',\n",
    "            metrics=[tf.keras.metrics.MeanSquaredError()])\n",
    "\n",
    "        history = linear_model.fit(\n",
    "            tf.convert_to_tensor(training),\n",
    "            tf.convert_to_tensor(labels),\n",
    "            epochs=100,\n",
    "            validation_split=0.2,\n",
    "            # Suppress logging.\n",
    "            verbose=1)\n",
    "        return linear_model\n",
    "\n",
    "    def createRF(training, labels, estim=1000, r_state=42, apply_scaler3=True):\n",
    "        # Import the model we are using\n",
    "        try:\n",
    "            for i in range(len(training)):\n",
    "                training[i] = list(training[i].values())\n",
    "        except Exception as e:\n",
    "            training = training\n",
    "        from sklearn.ensemble import RandomForestRegressor\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "        if apply_scaler3:\n",
    "            scaler3 = StandardScaler()\n",
    "            scaler3.fit(training)\n",
    "            data3 = scaler3.transform(training)\n",
    "        else:\n",
    "            data3 = training\n",
    "        # Instantiate model with 1000 decision trees\n",
    "        rf = RandomForestRegressor(n_estimators = estim, random_state = r_state)\n",
    "        # Train the model on training data\n",
    "        rf.fit(data3, labels)\n",
    "        return rf\n",
    "\n",
    "    def formatAvgPos(SVM=False,COLOR=False):\n",
    "        import numpy as np\n",
    "        avg_pos_temp = avgPos()\n",
    "        avg_pos = {}\n",
    "        ratings = []\n",
    "        if COLOR:\n",
    "            c = colorfulness()\n",
    "\n",
    "        for key, element in avg_pos_temp.items():\n",
    "            if not data.get(key) == None:\n",
    "                temp_data = []\n",
    "                shape = cv2.imread(directory + str(key) + \".png\").shape\n",
    "                #print(shape)\n",
    "                for i in range(8):\n",
    "                    if element.get(i) == None:\n",
    "                        temp_data.append(0)\n",
    "                        temp_data.append(0)\n",
    "                    else:\n",
    "                        temp_data.append(element[i][0]\n",
    "                        #/shape[1]\n",
    "                        )\n",
    "                        temp_data.append(element[i][1]\n",
    "                        #/shape[0]\n",
    "                        )\n",
    "                if COLOR:\n",
    "                    temp_data.append(c[int(key)])\n",
    "                if SVM:\n",
    "                    avg_pos[int(key)] = temp_data\n",
    "                    if data[key] >= 4.5:\n",
    "                        ratings.append(1)\n",
    "                    else:\n",
    "                        ratings.append(0)\n",
    "                else:\n",
    "                    avg_pos[int(key)] = temp_data\n",
    "                    ratings.append((data[key]))\n",
    "        return avg_pos,ratings \n",
    "        \n",
    "    def formatFreq(SVM=False,RANDOMFOREST=False):\n",
    "        import numpy as np\n",
    "        class_freq_temp = freqClass()\n",
    "        #print(class_freq_temp)\n",
    "        data_2 = {}\n",
    "        class_freq = {}\n",
    "\n",
    "        for key, value in class_freq_temp.items():\n",
    "            if not data.get(key) == None:\n",
    "                temp_val = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[]}\n",
    "                for i in range(8):\n",
    "                    if value.get(i) == None:\n",
    "                        temp_val[i] = 0\n",
    "                    else:\n",
    "                        temp_val[i] = value[i]\n",
    "                class_freq[key] = temp_val\n",
    "\n",
    "        for key in list(class_freq_temp.keys()):\n",
    "            if not data.get(key) == None:\n",
    "                data_2[key] = data[key]\n",
    "\n",
    "        return class_freq, data_2\n",
    "\n",
    "    def formatRaw(SVM=False, COLOR=False):\n",
    "        import numpy as np\n",
    "\n",
    "        freq_quad_temp = raw(raw_data)\n",
    "        freq_quad = []\n",
    "        quad_ratings = []\n",
    "        quad_ratings_binary = []\n",
    "\n",
    "        for key, value in freq_quad_temp.items():\n",
    "            if not data.get(key) == None:\n",
    "                freq_quad.append(value)\n",
    "                quad_ratings.append(data[key])\n",
    "                if data[key] >= 4:\n",
    "                    quad_ratings_binary.append(1)\n",
    "                else:\n",
    "                    quad_ratings_binary.append(0)\n",
    "        if SVM:\n",
    "            return freq_quad_temp, quad_ratings_binary\n",
    "        else:\n",
    "            return freq_quad_temp, quad_ratings\n",
    "\n",
    "    def formatQuad(SVM=False, COLOR=False):\n",
    "        import numpy as np\n",
    "\n",
    "        if COLOR:\n",
    "            c = colorfulness()\n",
    "\n",
    "        freq_quad_temp = freqQuad()\n",
    "        freq_quad = {}\n",
    "        quad_ratings = []\n",
    "        quad_ratings_binary = []\n",
    "\n",
    "        for key, value in freq_quad_temp.items():\n",
    "            if not data.get(key) == None:\n",
    "                if COLOR:\n",
    "                    value.append(c[key])\n",
    "                freq_quad[key] = value\n",
    "                quad_ratings.append(data[key])\n",
    "                if data[key] >= 4:\n",
    "                    quad_ratings_binary.append(1)\n",
    "                else:\n",
    "                    quad_ratings_binary.append(0)\n",
    "        if SVM:\n",
    "            return freq_quad, quad_ratings_binary\n",
    "        else:\n",
    "            return freq_quad, quad_ratings\n",
    "\n",
    "    def integrateData(input):\n",
    "        for key, value in input.items():\n",
    "            if training.get(key) == None:\n",
    "                training[key] = value\n",
    "            else:\n",
    "                training[key].extend(value)\n",
    "                \n",
    "    def makeTrainTest(SVM=False, threshold=4):\n",
    "        for key, value in training.items():\n",
    "            if not data.get(key) == None:\n",
    "                a.append(value)\n",
    "                if SVM:\n",
    "                    data_index = data[key]\n",
    "                    if data_index > threshold:\n",
    "                        b.append(1)\n",
    "                    else:\n",
    "                        b.append(0)\n",
    "                else:\n",
    "                    b.append(data[key])\n",
    "\n",
    "    import csv\n",
    "    path = r\"dataset\\preprocess\\train_means_list.csv\"\n",
    "    data = {}\n",
    "    with open(path) as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            if \"english_resized\" in row[0]:\n",
    "                key = int(row[0][row[0].rfind(\"/\")+1:row[0].rfind(\".\")])\n",
    "                value = float(row[1])\n",
    "                data[key] = value\n",
    "    training = {}\n",
    "    a = []\n",
    "    b = []\n",
    "    s = None\n",
    "    r = None\n",
    "    model = None\n",
    "    if modeltype == \"SVM\":\n",
    "        s = True\n",
    "    else:\n",
    "        s = False\n",
    "    if modeltype == \"RF\":\n",
    "        r = True\n",
    "    else:\n",
    "        r = False\n",
    "    if avgPosition:\n",
    "        integrateData(formatAvgPos(SVM=s,COLOR=c)[0])\n",
    "    if quadrants:\n",
    "        integrateData(formatQuad(SVM=s,COLOR=c)[0])\n",
    "    if classfreq:\n",
    "        integrateData(formatFreq(SVM=s,RANDOMFOREST=r)[0])\n",
    "    if raw:\n",
    "        integrateData(formatRaw(SVM=s,COLOR=c)[0])\n",
    "    makeTrainTest(SVM=s)\n",
    "    if r:\n",
    "        model = createRF(a,b)\n",
    "    if s:\n",
    "        model = createSVM(a,b)\n",
    "    else:\n",
    "        model = createLin(a,b)\n",
    "    return model\n",
    "\n",
    "#m = mixFeatures(True,False,True,False,\"SVM\",False)\n",
    "\n",
    "#m.predict([[0,1,0,2,3,1,3,5,1,3,7,3,1,8,2,6,3,0,0,0,0,0,0,0]])\n",
    "print('Done feature mixer')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix Features Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def mixValid(x,avgPosition,quadrants,classfreq,raw,modeltype, c):\n",
    "    def formatAvgPos_X(data_2=None, SVM=False):\n",
    "        import numpy as np\n",
    "\n",
    "        if data_2 == None:\n",
    "            avg_pos_temp = avgPos()\n",
    "        else:\n",
    "            def avgPosOfGiven(d):\n",
    "                temp = list(d.values())\n",
    "                avg_element_position = {}\n",
    "                for i in range(len(temp)):\n",
    "                    avg_pixel_position_for_class = {}\n",
    "                    count = {}\n",
    "                    for element in temp[i]:\n",
    "                        if avg_pixel_position_for_class.get(int(element[5])) == None:\n",
    "                            avg_pixel_position_for_class[int(element[5])] = ((float(element[0])+float(element[2]))/2,(float(element[1])+float(element[3]))/2)\n",
    "                            count[int(element[5])] = 1\n",
    "                        else:\n",
    "                            count[int(element[5])] += 1\n",
    "                            avg_pixel_position_for_class[int(element[5])] = ((((float(element[0])+float(element[2]))/2)+avg_pixel_position_for_class[int(element[5])][0])/count[int(element[5])],(((float(element[1])+float(element[3]))/2)+avg_pixel_position_for_class[int(element[5])][0])/count[int(element[5])])\n",
    "                            \n",
    "                    avg_element_position[int(image_names[i])] = avg_pixel_position_for_class\n",
    "                    #print(count)\n",
    "\n",
    "                return avg_element_position\n",
    "            avg_pos_temp = avgPosOfGiven(raw_data)\n",
    "        avg_pos = {}\n",
    "        ratings = []\n",
    "\n",
    "        for key, element in avg_pos_temp.items():\n",
    "            if not data.get(key) == None:\n",
    "                temp_data = []\n",
    "                shape = cv2.imread(directory + str(key) + \".png\").shape\n",
    "                #print(shape)\n",
    "                for i in range(8):\n",
    "                    if element.get(i) == None:\n",
    "                        temp_data.append(0)\n",
    "                        temp_data.append(0)\n",
    "                    else:\n",
    "                        temp_data.append(element[i][0]\n",
    "                        #/shape[1]\n",
    "                        )\n",
    "                        temp_data.append(element[i][1]\n",
    "                        #/shape[0]\n",
    "                        )\n",
    "                if SVM:\n",
    "                    avg_pos[int(key)] = temp_data\n",
    "                    if data[key] >= 4.5:\n",
    "                        ratings.append(1)\n",
    "                    else:\n",
    "                        ratings.append(0)\n",
    "                else:\n",
    "                    avg_pos[int(key)] = temp_data\n",
    "                    ratings.append((data[key]))\n",
    "        return avg_pos,ratings\n",
    "    def formatFreq_X(data_2=None, SVM=False,RANDOMFOREST=False):\n",
    "        import numpy as np\n",
    "\n",
    "        if data_2==None:\n",
    "            class_freq_temp = freqClass()\n",
    "        else:\n",
    "            \n",
    "            def freqClass(d):\n",
    "                data = {}\n",
    "                temp = list(d.values())\n",
    "                for i in range(len(temp)):\n",
    "                    per_image_data = {}\n",
    "                    for element in temp[i]:\n",
    "                        if per_image_data.get(int(element[5])) == None:\n",
    "                            per_image_data[int(element[5])] = 1\n",
    "                        else:\n",
    "                            per_image_data[int(element[5])] = per_image_data[int(element[5])] + 1\n",
    "                    data[int(image_names[i])] = per_image_data\n",
    "                return data\n",
    "            #class_freq_temp = freqClass(raw_data)\n",
    "            class_freq_temp = freqClass(raw_data)\n",
    "        #print(class_freq_temp)\n",
    "\n",
    "        data_3 = {}\n",
    "\n",
    "        class_freq = {}\n",
    "\n",
    "        for key, value in class_freq_temp.items():\n",
    "            if not data.get(key) == None:\n",
    "                temp_val = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[]}\n",
    "                for i in range(8):\n",
    "                    if value.get(i) == None:\n",
    "                        temp_val[i] = 0\n",
    "                    else:\n",
    "                        temp_val[i] = value[i]\n",
    "                class_freq[key] = list(temp_val.values())\n",
    "\n",
    "        for key in list(class_freq_temp.keys()):\n",
    "            if not data.get(key) == None:\n",
    "                data_3[key] = data[key]\n",
    "\n",
    "        return class_freq, data_3\n",
    "    def formatRaw_X(data_2=None, SVM=False):\n",
    "        import numpy as np\n",
    "\n",
    "        if data_2 == None:\n",
    "            freq_quad_temp = raw(raw_data)\n",
    "        else:\n",
    "            freq_quad_temp=raw(data_2)\n",
    "        freq_quad = []\n",
    "        quad_ratings = []\n",
    "        quad_ratings_binary = []\n",
    "\n",
    "        for key, value in freq_quad_temp.items():\n",
    "            if not data.get(key) == None:\n",
    "                freq_quad.append(value)\n",
    "                quad_ratings.append(data[key])\n",
    "                if data[key] >= 4:\n",
    "                    quad_ratings_binary.append(1)\n",
    "                else:\n",
    "                    quad_ratings_binary.append(0)\n",
    "        if SVM:\n",
    "            return freq_quad_temp, quad_ratings_binary\n",
    "        else:\n",
    "            return freq_quad_temp, quad_ratings\n",
    "    def formatQuad_X(data_2=None, SVM=False):\n",
    "        import numpy as np\n",
    "        \n",
    "        if data_2 == None:\n",
    "            freq_quad_temp = freqQuad()\n",
    "        else:\n",
    "            def freqQuad(d):\n",
    "                class_per_quadrant = {}\n",
    "                temp = list(d.values())\n",
    "                for i in range(len(temp)):\n",
    "                    temp_data_holder = [{},{},{},{}]\n",
    "                    temp_data_holder_2 = []\n",
    "                    temp_image_name = image_names[i]\n",
    "                    temp_image = cv2.imread(directory + temp_image_name + '.png')\n",
    "                    w = temp_image.shape[0]\n",
    "                    h = temp_image.shape[1]\n",
    "                    for element in temp[i]:\n",
    "                        center_X = (element[0]+element[2])/2\n",
    "                        center_Y = (element[1]+element[3])/2\n",
    "                        if center_X >= w/2 and center_Y >= h/2:\n",
    "                            if temp_data_holder[0].get(int(element[5])) == None:\n",
    "                                temp_data_holder[0][int(element[5])] = 1\n",
    "                            else:\n",
    "                                temp_data_holder[0][int(element[5])] = temp_data_holder[0][int(element[5])] + 1\n",
    "                        if center_X < w/2 and center_Y >= h/2:\n",
    "                            if temp_data_holder[1].get(int(element[5])) == None:\n",
    "                                temp_data_holder[1][int(element[5])] = 1\n",
    "                            else:\n",
    "                                temp_data_holder[1][int(element[5])] = temp_data_holder[1][int(element[5])] + 1\n",
    "                        if center_X < w/2 and center_Y < h/2:\n",
    "                            if temp_data_holder[2].get(int(element[5])) == None:\n",
    "                                temp_data_holder[2][int(element[5])] = 1\n",
    "                            else:\n",
    "                                temp_data_holder[2][int(element[5])] = temp_data_holder[2][int(element[5])] + 1\n",
    "                        if center_X >= w/2 and center_Y < h/2:\n",
    "                            if temp_data_holder[3].get(int(element[5])) == None:\n",
    "                                temp_data_holder[3][int(element[5])] = 1\n",
    "                            else:\n",
    "                                temp_data_holder[3][int(element[5])] = temp_data_holder[3][int(element[5])] + 1\n",
    "                    for quadrant in temp_data_holder:\n",
    "                        for i in range(8):\n",
    "                            if quadrant.get(i) == None:\n",
    "                                temp_data_holder_2.append(0)\n",
    "                            else:\n",
    "                                temp_data_holder_2.append(quadrant[i])\n",
    "                    class_per_quadrant[int(temp_image_name)] = temp_data_holder_2\n",
    "                return class_per_quadrant\n",
    "            freq_quad_temp = freqQuad(raw_data)\n",
    "        freq_quad = {}\n",
    "        quad_ratings = []\n",
    "        quad_ratings_binary = []\n",
    "\n",
    "        for key, value in freq_quad_temp.items():\n",
    "            if not data.get(key) == None:\n",
    "                freq_quad[key] = value\n",
    "                quad_ratings.append(data[key])\n",
    "                if data[key] >= 4:\n",
    "                    quad_ratings_binary.append(1)\n",
    "                else:\n",
    "                    quad_ratings_binary.append(0)\n",
    "        if SVM:\n",
    "            return freq_quad, quad_ratings_binary\n",
    "        else:\n",
    "            return freq_quad, quad_ratings\n",
    "    \n",
    "    d = Data(directory=x,pt=r\"C:\\Users\\woprg\\Desktop\\CCIR\\LearningML\\TrainingYOLOv7_3\\yolov5\\runs\\train\\yolo_website6\\weights\\best.pt\")\n",
    "    raw_data_X = d.filter_confidence()\n",
    "    #print(raw_data)\n",
    "    import csv\n",
    "    path = r\"dataset\\preprocess\\train_means_list.csv\"\n",
    "    data = {}\n",
    "    with open(path) as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            if \"english_resized\" in row[0]:\n",
    "                key = int(row[0][row[0].rfind(\"/\")+1:row[0].rfind(\".\")])\n",
    "                value = float(row[1])\n",
    "                data[key] = value\n",
    "    testing = {}\n",
    "\n",
    "    #avgPosition,quadrants,classfreq,raw,modeltype,\n",
    "    if avgPosition:\n",
    "        aP = formatAvgPos_X(data_2=raw_data_X,SVM=False)[0]\n",
    "        for key, value in aP.items():\n",
    "            if testing.get(key) == None:\n",
    "                testing[key] = value\n",
    "            else:\n",
    "                testing[key].extend(value)\n",
    "    if quadrants:\n",
    "        q = formatQuad_X(data_2=raw_data_X,SVM=False)[0]\n",
    "        for key, value in q.items():\n",
    "            if testing.get(key) == None:\n",
    "                testing[key] = value\n",
    "            else:\n",
    "                testing[key].extend(value)\n",
    "    if classfreq:\n",
    "        f = formatFreq_X(data_2=raw_data_X,SVM=False)[0]\n",
    "        for key, value in f.items():\n",
    "            if testing.get(key) == None:\n",
    "                testing[key] = value\n",
    "            else:\n",
    "                testing[key].extend(value)\n",
    "    if raw:\n",
    "        r = formatRaw_X(data_2=raw_data_X,SVM=False)[0]\n",
    "        for key, value in r.items():\n",
    "            if testing.get(key) == None:\n",
    "                testing[key] = value\n",
    "            else:\n",
    "                testing[key].extend(value)\n",
    "    model_type = modeltype\n",
    "    model = mixFeatures(avgPosition,quadrants,classfreq,raw,model_type,False)\n",
    "    predictions_temp = model.predict(list(testing.values()))\n",
    "    predictions = []\n",
    "    #print(predictions_temp)\n",
    "    for prediction in predictions_temp:\n",
    "        if model_type == \"SVM\":\n",
    "            predictions.append(prediction)\n",
    "        else:\n",
    "            predictions.append(prediction[0])\n",
    "    actual = []\n",
    "    for key in list(testing.keys()):\n",
    "        actual.append(data[key])\n",
    "    def removeBadValues(act, pred):\n",
    "        act_2 = act.copy()\n",
    "        pred_2 = pred.copy()\n",
    "        count_removed = 0\n",
    "        for i in range(len(pred)):\n",
    "            if pred[i]<0:\n",
    "                pred_2.pop(i-count_removed)\n",
    "                act_2.pop(i-count_removed)\n",
    "                count_removed+=1\n",
    "        return act_2, pred_2\n",
    "    actual, predictions = removeBadValues(actual, predictions)\n",
    "\n",
    "    if model_type == \"SVM\":\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] >= 4:\n",
    "                actual[i] = 1\n",
    "            else:\n",
    "                actual[i] = 0\n",
    "\n",
    "    accuracy = -1\n",
    "\n",
    "    if model_type == \"SVM\":\n",
    "        correct = 0\n",
    "        for i in range(len(actual)):\n",
    "            if actual[i] == predictions[i]:\n",
    "                correct = correct + 1\n",
    "        accuracy = float(correct/len(actual))\n",
    "    else:\n",
    "        accuracy = mean_squared_error(actual, predictions)\n",
    "\n",
    "    return predictions, actual, accuracy, testing\n",
    "\n",
    "# False, False, True, False is broken \"TypeError: float() argument must be a string or a real number, not 'dict'\"\n",
    "# True, True, False, False and True, False, False, False are both 0.64\n",
    "# False, True, False, False is 0.76\n",
    "\n",
    "#mixValid(\"dataset/images/english/\",True,True,True,False,\"SVM\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to C:\\Users\\woprg/.cache\\torch\\hub\\master.zip\n",
      "YOLOv5  2022-11-2 Python-3.10.4 torch-1.12.1+cu116 CUDA:0 (NVIDIA GeForce RTX 3060 Laptop GPU, 6144MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 213 layers, 7031701 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "with open(\"results.txt\",\"w\") as f:\n",
    "    for model_aAabBbcCc in [\n",
    "        #\"LIN\",\n",
    "        \"SVM\",\n",
    "        #\"RF\"\n",
    "        ]:\n",
    "        for aAa in [\n",
    "            #True,\n",
    "            False]:\n",
    "            for bBb in [\n",
    "                True,\n",
    "                #False\n",
    "                ]:\n",
    "                for cCc in [\n",
    "                    #True,\n",
    "                    False\n",
    "                    ]:\n",
    "                    if(not aAa and not bBb and not cCc):\n",
    "                        continue\n",
    "                    variable_aaa = mixValid(\"dataset/images/english/\",aAa,bBb,cCc,False,model_aAabBbcCc,False)\n",
    "                    data_list = \"\"\n",
    "                    for i in range(len(variable_aaa[0])):\n",
    "                        '''\n",
    "                        if variable_aaa[0][i] == 1:\n",
    "                            data_list = str(variable_aaa[0][i]) + \",\" + str(list(variable_aaa[3].values())[i]).replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\") + \"\\n\" + data_list\n",
    "                        else:\n",
    "                            data_list = data_list + str(variable_aaa[0][i]) + \",\" + str(list(variable_aaa[3].values())[i]).replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\") + \"\\n\"\n",
    "                        '''\n",
    "                        data_list = data_list + str(variable_aaa[0][i]) + \",\" + str(list(variable_aaa[3].values())[i]).replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\") + \"\\n\"\n",
    "                    f.write(model_aAabBbcCc + \" \" + str(aAa) + \" \" + str(bBb) + \" \" + str(cCc) + \" \" + str(variable_aaa[2]) + \"\\n\"\n",
    "                    #+ str(variable_aaa[3]) + \"\\n\" + str(variable_aaa[0])\n",
    "                    + data_list\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data For McNemar's Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "\n",
    "with open(\"mcnemars.csv\", \"w\", newline='') as csvfile:\n",
    "    fieldnames = ['Instance', 'SVM Correct', 'Guess Correct']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for a1a in [True,False]:\n",
    "        for b2b in [True,False]:\n",
    "            for c3c in [True,False]:\n",
    "                if(not a1a and not b2b and not c3c):\n",
    "                    continue\n",
    "                validation_data = mixValid(\"dataset/images/english/\",a1a,b2b,c3c,False,\"SVM\",False)\n",
    "                for i in range(len(validation_data[0])):\n",
    "                    predicted = validation_data[0][i]\n",
    "                    actual = validation_data[1][i]\n",
    "                    guess = random.choice([0,1])\n",
    "                    writer.writerow({\"Instance\":str(i),\"SVM Correct\":str(predicted==actual),\"Guess Correct\":str(guess==actual)})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
